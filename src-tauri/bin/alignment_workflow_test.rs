// alignment_workflow_test.rs - åˆåƒå·¥ä½œæµæ¨¡å—æµ‹è¯•
// é‡ç‚¹æµ‹è¯•ç¦»çº¿å¯éªŒè¯çš„æ ¸å¿ƒé€»è¾‘

use std::time::Instant;
use opencv::{core, imgcodecs, prelude::*};
use merging_image_lib::modules::alignment_workflow::{
    AlignmentWorkflow, DetectionResult, DetectionStage, FrameData
};

/// å·¥ä½œæµæµ‹è¯•å™¨ (ç¦»çº¿æ¨¡å¼)
pub struct AlignmentWorkflowTest {
    test_image_left: core::Mat,
    test_image_right: core::Mat,
}

impl AlignmentWorkflowTest {
    /// åˆ›å»ºæµ‹è¯•å®ä¾‹
    pub fn new() -> Result<Self, Box<dyn std::error::Error>> {
        println!("ğŸ”§ åˆå§‹åŒ–å·¥ä½œæµæµ‹è¯•å™¨ (ç¦»çº¿æ¨¡å¼)...");
        
        // ç¡®å®šæ­£ç¡®çš„æ–‡ä»¶è·¯å¾„
        let exe_path = std::env::current_exe()?;
        let exe_dir = exe_path.parent().unwrap();
        let src_tauri_dir = exe_dir.parent().unwrap().parent().unwrap();
        
        // æ„é€ ç»å¯¹è·¯å¾„
        let left_image_path = src_tauri_dir.join("src/tests/data/benchmark/left_calibration.bmp");
        let right_image_path = src_tauri_dir.join("src/tests/data/benchmark/right_calibration.bmp");
        
        println!("ğŸ“ åŠ è½½æµ‹è¯•å›¾åƒ:");
        println!("   å·¦å›¾: {:?}", left_image_path);
        println!("   å³å›¾: {:?}", right_image_path);
        
        // åŠ è½½æµ‹è¯•å›¾åƒ
        let left_image = imgcodecs::imread(
            left_image_path.to_str().unwrap(),
            imgcodecs::IMREAD_GRAYSCALE,
        )?;
        let right_image = imgcodecs::imread(
            right_image_path.to_str().unwrap(),
            imgcodecs::IMREAD_GRAYSCALE,
        )?;
        
        if left_image.empty() || right_image.empty() {
            return Err("æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„".into());
        }
        
        println!("âœ“ æµ‹è¯•å›¾åƒåŠ è½½æˆåŠŸ");
        println!("   å·¦å›¾å°ºå¯¸: {}x{}", left_image.cols(), left_image.rows());
        println!("   å³å›¾å°ºå¯¸: {}x{}", right_image.cols(), right_image.rows());
        
        Ok(Self {
            test_image_left: left_image,
            test_image_right: right_image,
        })
    }
    
    /// è¿è¡Œæ‰€æœ‰ç¦»çº¿æµ‹è¯•
    pub fn run_tests(&mut self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ§ª å¼€å§‹å·¥ä½œæµç¦»çº¿æµ‹è¯•...");
        println!("{}", "=".repeat(60));
        
        // 1. æµ‹è¯•æ•°æ®è½¬æ¢åŠŸèƒ½
        self.test_raw_data_conversion()?;
        
        // 2. æµ‹è¯•å•å¸§æ£€æµ‹ (éœ€è¦Mock AppHandle)
        println!("âš ï¸ å•å¸§æ£€æµ‹æµ‹è¯•éœ€è¦Tauri AppHandleï¼Œè·³è¿‡");
        println!("   å»ºè®®: åœ¨é›†æˆæµ‹è¯•ç¯å¢ƒä¸­æµ‹è¯•æ­¤åŠŸèƒ½");
        
        // 3. æµ‹è¯•åœ†å¿ƒæ£€æµ‹
        println!("âš ï¸ åœ†å¿ƒæ£€æµ‹æµ‹è¯•éœ€è¦åˆå§‹åŒ–çš„AlignmentWorkflowï¼Œè·³è¿‡");
        println!("   å»ºè®®: ç›´æ¥ä½¿ç”¨alignment.rsè¿›è¡Œåœ†å¿ƒæ£€æµ‹æµ‹è¯•");
        
        // 4. æµ‹è¯•ç¯å½¢ç¼“å†²åŒºé€»è¾‘
        self.test_ring_buffer_logic()?;
        
        // 5. æµ‹è¯•é˜¶æ®µè½¬æ¢é€»è¾‘
        self.test_stage_transitions()?;
        
        println!("{}", "=".repeat(60));
        println!("âœ… ç¦»çº¿æµ‹è¯•å®Œæˆ");
        println!("ğŸ’¡ å»ºè®®: åœ¨æœ‰è®¾å¤‡çš„ç¯å¢ƒä¸­è¿›è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•");
        Ok(())
    }
    
    /// æµ‹è¯•åŸå§‹æ•°æ®è½¬æ¢
    fn test_raw_data_conversion(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ” æµ‹è¯•åŸå§‹æ•°æ®è½¬æ¢åŠŸèƒ½...");
        
        // å°†æµ‹è¯•å›¾åƒè½¬æ¢ä¸ºåŸå§‹æ•°æ®
        let left_data = self.mat_to_raw_data(&self.test_image_left)?;
        let right_data = self.mat_to_raw_data(&self.test_image_right)?;
        
        println!("   å·¦å›¾åŸå§‹æ•°æ®å¤§å°: {} bytes", left_data.len());
        println!("   å³å›¾åŸå§‹æ•°æ®å¤§å°: {} bytes", right_data.len());
        
        // æµ‹è¯•æ•°æ®è½¬æ¢å›Mat (ä½¿ç”¨AlignmentWorkflowçš„ç§æœ‰æ–¹æ³•é€»è¾‘)
        let reconstructed_left = self.test_raw_data_to_mat(&left_data, 2448, 2048)?;
        let reconstructed_right = self.test_raw_data_to_mat(&right_data, 2448, 2048)?;
        
        // éªŒè¯è½¬æ¢ç»“æœ
        if reconstructed_left.cols() == self.test_image_left.cols() &&
           reconstructed_left.rows() == self.test_image_left.rows() {
            println!("âœ“ å·¦å›¾æ•°æ®è½¬æ¢éªŒè¯é€šè¿‡");
        } else {
            println!("âŒ å·¦å›¾æ•°æ®è½¬æ¢éªŒè¯å¤±è´¥");
        }
        
        if reconstructed_right.cols() == self.test_image_right.cols() &&
           reconstructed_right.rows() == self.test_image_right.rows() {
            println!("âœ“ å³å›¾æ•°æ®è½¬æ¢éªŒè¯é€šè¿‡");
        } else {
            println!("âŒ å³å›¾æ•°æ®è½¬æ¢éªŒè¯å¤±è´¥");
        }
        
        println!("âœ… æ•°æ®è½¬æ¢æµ‹è¯•å®Œæˆ");
        Ok(())
    }
    
    /// æµ‹è¯•ç¯å½¢ç¼“å†²åŒºé€»è¾‘
    fn test_ring_buffer_logic(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ” æµ‹è¯•ç¯å½¢ç¼“å†²åŒºé€»è¾‘...");
        
        use merging_image_lib::modules::alignment_workflow::RingBuffer;
        
        let mut buffer = RingBuffer::new(3); // å®¹é‡ä¸º3çš„ç¼“å†²åŒº
        
        // æµ‹è¯•æ¨é€é€»è¾‘
        for i in 0..5 {
            let frame = FrameData {
                left_image: vec![i as u8; 100], // æ¨¡æ‹Ÿå›¾åƒæ•°æ®
                right_image: vec![i as u8; 100],
                timestamp: Instant::now(),
            };
            buffer.push(frame);
            
            let (total, dropped, drop_rate) = buffer.get_stats();
            println!("   æ¨é€å¸§{}: æ€»æ•°={}, ä¸¢å¸§={}, ä¸¢å¸§ç‡={:.1}%, å½“å‰å¤§å°={}", 
                    i, total, dropped, drop_rate, buffer.len());
        }
        
        // éªŒè¯ç¼“å†²åŒºè¡Œä¸º
        assert_eq!(buffer.len(), 3, "ç¼“å†²åŒºå¤§å°åº”è¯¥è¢«é™åˆ¶åœ¨å®¹é‡å†…");
        
        let (total, dropped, drop_rate) = buffer.get_stats();
        assert_eq!(total, 5, "æ€»æ¨é€æ•°åº”è¯¥ä¸º5");
        assert_eq!(dropped, 2, "åº”è¯¥ä¸¢å¼ƒ2å¸§");
        assert_eq!(drop_rate, 40.0, "ä¸¢å¸§ç‡åº”è¯¥ä¸º40%");
        
        println!("âœ… ç¯å½¢ç¼“å†²åŒºæµ‹è¯•é€šè¿‡");
        Ok(())
    }
    
    /// æµ‹è¯•é˜¶æ®µè½¬æ¢é€»è¾‘
    fn test_stage_transitions(&self) -> Result<(), Box<dyn std::error::Error>> {
        println!("ğŸ” æµ‹è¯•é˜¶æ®µè½¬æ¢é€»è¾‘...");
        
        // æµ‹è¯•é˜¶æ®µè½¬æ¢åºåˆ—
        let transitions = vec![
            (DetectionStage::LeftEyePoseCheck, "RightEyePoseCheck"),
            (DetectionStage::RightEyePoseCheck, "DualEyeAlignment"), 
            (DetectionStage::DualEyeAlignment, "Completed"),
        ];
        
        for (current, expected_next) in transitions {
            let next = self.simulate_stage_transition(&current);
            println!("   {:?} -> {:?}", current, next);
            
            match next {
                Some(DetectionStage::RightEyePoseCheck) if expected_next == "RightEyePoseCheck" => {
                    println!("   âœ“ è½¬æ¢æ­£ç¡®");
                },
                Some(DetectionStage::DualEyeAlignment) if expected_next == "DualEyeAlignment" => {
                    println!("   âœ“ è½¬æ¢æ­£ç¡®");
                },
                Some(DetectionStage::Completed) if expected_next == "Completed" => {
                    println!("   âœ“ è½¬æ¢æ­£ç¡®");
                },
                _ => {
                    println!("   âŒ è½¬æ¢é”™è¯¯");
                }
            }
        }
        
        println!("âœ… é˜¶æ®µè½¬æ¢æµ‹è¯•å®Œæˆ");
        Ok(())
    }
    
    /// è¾…åŠ©æ–¹æ³•ï¼šå°†Matè½¬æ¢ä¸ºåŸå§‹æ•°æ®
    fn mat_to_raw_data(&self, mat: &core::Mat) -> Result<Vec<u8>, opencv::Error> {
        let data_size = (mat.cols() * mat.rows()) as usize;
        let mut raw_data = vec![0u8; data_size];
        
        unsafe {
            let mat_data = mat.data();
            std::ptr::copy_nonoverlapping(mat_data, raw_data.as_mut_ptr(), data_size);
        }
        
        Ok(raw_data)
    }
    
    /// è¾…åŠ©æ–¹æ³•ï¼šæµ‹è¯•åŸå§‹æ•°æ®åˆ°Matçš„è½¬æ¢ (å¤åˆ¶AlignmentWorkflowçš„é€»è¾‘)
    fn test_raw_data_to_mat(&self, data: &[u8], width: i32, height: i32) -> Result<core::Mat, opencv::Error> {
        // åˆ›å»ºç©ºçš„Mat
        let mut mat = core::Mat::new_rows_cols_with_default(
            height,
            width,
            core::CV_8UC1,
            core::Scalar::default(),
        )?;
        
        // å°†æ•°æ®æ‹·è´åˆ°Matä¸­
        let mat_data = mat.data_mut();
        let expected_size = (width * height) as usize;
        
        if data.len() >= expected_size {
            unsafe {
                std::ptr::copy_nonoverlapping(
                    data.as_ptr(),
                    mat_data,
                    expected_size,
                );
            }
        } else {
            return Err(opencv::Error::new(
                opencv::core::StsError, 
                format!("æ•°æ®é•¿åº¦ä¸è¶³: éœ€è¦{}å­—èŠ‚ï¼Œå®é™…{}å­—èŠ‚", expected_size, data.len())
            ));
        }
        
        Ok(mat)
    }
    
    /// è¾…åŠ©æ–¹æ³•ï¼šæ¨¡æ‹Ÿé˜¶æ®µè½¬æ¢é€»è¾‘
    fn simulate_stage_transition(&self, current: &DetectionStage) -> Option<DetectionStage> {
        match current {
            DetectionStage::LeftEyePoseCheck => Some(DetectionStage::RightEyePoseCheck),
            DetectionStage::RightEyePoseCheck => Some(DetectionStage::DualEyeAlignment),
            DetectionStage::DualEyeAlignment => Some(DetectionStage::Completed),
            _ => None,
        }
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ å¯åŠ¨å·¥ä½œæµç¦»çº¿æµ‹è¯•ç¨‹åº");
    println!("ğŸ“ æ³¨æ„: è¿™æ˜¯ç¦»çº¿æµ‹è¯•ï¼Œä¸æ¶‰åŠçœŸå®ç¡¬ä»¶");
    
    let mut test = AlignmentWorkflowTest::new()?;
    test.run_tests()?;
    
    println!("ğŸ‰ ç¦»çº¿æµ‹è¯•ç¨‹åºå®Œæˆ");
    println!("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:");
    println!("   1. åœ¨æœ‰è®¾å¤‡ç¯å¢ƒä¸­è¿›è¡Œå®Œæ•´é›†æˆæµ‹è¯•");
    println!("   2. æµ‹è¯•SimpleCameraManagerä¸çœŸå®ç¡¬ä»¶çš„é›†æˆ");
    println!("   3. éªŒè¯é‡‡é›†çº¿ç¨‹çš„å®é™…æ€§èƒ½è¡¨ç°");
    Ok(())
} 